---
created: 2022-11-14T09:14:48 (UTC -08:00)
tags: []
source: https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23
author: Melanie Gee
---

# Indexes compared: reflections on the benefits of peer review exercises | Indexer (The)

> ## Excerpt
> Book indexers are finding ways to engage in peer review exercises, which mainly involve a group of indexers preparing their own indexes for the same text and then comparing them. They are doing thi...

---
Publication: The Indexer: The International Journal of Indexing

Volume 39, Number 3

## Abstract

Book indexers are finding ways to engage in peer review exercises, which mainly involve a group of indexers preparing their own indexes for the same text and then comparing them. They are doing this both online and in person, using discussion forums, tutorials and locally run groups. Melanie Gee reports on the peer review exercises organized by the UK Society of Indexers. She concludes that peer exercises not only build skills but also provide social connections for otherwise solitary professional indexers.

## Introduction

We all know that indexing books can be a solitary business. For many, that is part of the appeal. For some commissions the indexer may be in periodic contact with the client, running things past them or getting helpful (or at least well-intentioned) suggestions from the author. But for others, the indexer works away in happy isolation, perhaps receiving an acknowledgement that it was submitted on time, or a ‘thanks, great job!’ The invoice is fired off, records are updated, and the indexer moves on to the next project. Perhaps there is a niggling doubt about how the index hung together. It seemed to work well enough, but maybe it could have been approached differently. Would someone else have approached it differently? Better, perhaps?

Indexing forums and email discussion lists are, of course, a lifesaver for those thorny issues that we all come across from time to time, such as problems with indexing software or quick checks on ‘how should I index this person whose name is a bit tricky?’ Most of us won’t have the time or inclination, however, to routinely check through one another’s indexes – ‘peer review’ in the conventional sense – although there is a community of indexers who are willing to do this.

Index Peer Review is an email list on Groups.io dedicated to peer-reviewing indexes.<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn1" role="doc-noteref" id="body-ref-fn1">1</a></sup> It was begun as a Yahoo group by Martha Osgood in 1999,<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn2" role="doc-noteref" id="body-ref-fn2">2</a></sup> and when she retired in 2019, Ælfwine Mischler took over as owner and moderator. Group members can ask for volunteers to review their indexes, whether they are written for practice or for clients. Sometimes members request a review after they have submitted the index, for their own learning, for instance if they are working in a new subject area. There is often some emailing back and forth as the reviewees ask for clarification or explain their reasons for indexing decisions to the reviewer; only the reviewee has actually read the book so there may be good reasons for these decisions.

More formally, as a pre-qualification indexing assignment (PIA) for the UK Society of Indexers (SI), student indexers prepare an index to an unindexed (or inadequately indexed) complete book or document of between 150 and 200 pages. They send their index, along with the book or document, to an experienced indexer who provides detailed comments and constructive advice on the index. For many new indexers, this will be their first attempt at a full-length index so the feedback is invaluable and serves as a confidence boost as they venture forth.

Much can be learned when a group of indexers look at the same text, prepare their own indexes to it, and then compare notes. In the SI we (rather confusingly) refer to this as a ‘peer review’ exercise and it is this type of peer review that is the focus of this article. Drawing from my own, and others’, experiences of leading and participating in peer review exercises, I discuss the benefits of participating in different types of peer review exercises, outline some advantages and disadvantages of different modes of delivery, and suggest strategies for facilitating them successfully.

## Group online tutorials for students

Group online tutorials were introduced as a compulsory element of the SI training course in 2007 ([Hudson, 2020](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#core-R3)); students must participate in at least three tutorials, ideally spaced out as they progress through the course, and ideally with different tutors so that they benefit from a range of texts, perspectives and approaches. Each tutorial runs over four weeks, during which a group of five to ten students compile indexes to a set text during the first two weeks, and compare and discuss their indexes under the guidance of an experienced indexer during the second two weeks. The tutorials run via an asynchronous email discussion list, each discussion topic running for two or three days to enable students to participate when it suits them. Although they are a formal course requirement, the tone of tutorials is informal and supportive. To obtain the most benefit from the tutorials, students should expect to take around five to six hours over the course of the discussion phase; those who are able to devote more time naturally benefit more, but most students are juggling tutorials with other work and family commitments so this can sometimes be difficult.

Tutors select texts that are 30–40 pages long, accessible but not trivial to index, and not too specialized. It can be difficult finding self-contained publications of the right length that fit all these criteria, so extracts from longer texts that stand alone well can also be used. The tutor needs to be confident indexing the subject matter themselves, of course – they need to have experience of what ‘works’ when indexing that type of text, and they share their own index at the end of the tutorial.

The tutor introduces three main discussion topics and one optional weekend topic for the keen. Typically, a new topic will be introduced by questions along the lines of ‘How did you tackle X? Did you encounter any problems/challenges? And would you do it differently now that you’ve seen everyone else’s index?’ although it is possible to be a bit more creative and design different activities that achieve essentially the same reflective processes. No one tutorial can cover all the bases, but across three tutorials students would normally expect to confront the following aspects of indexing at least once: subheadings, cross-references, indexing tables and illustrations, the metatopic, indexable concepts versus passing mentions, sought versus unsought terms and indexing certain classes of proper names as the texts dictate. Additionally, towards the end of the tutorial students are invited to raise any queries arising from the text, from the tutor’s example index or about the training course in general.

Tutorials are a lot of hard work for students and tutors alike; the discussion, although asynchronous, is necessarily rather fast-moving. I ran my first one as a tutor earlier this year but benefited from them greatly when I was a student indexer. Whilst the students’ indexes are not marked and individual feedback is not given, students take away a lot of learning points. (See [Figure 1](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F1) for an insight into the experiences of Nicola Green, a current student.)

![](https://www.liverpooluniversitypress.co.uk/cms/10.3828/indexer.2021.23/asset/5f1bebcb-6c47-4ed0-b22a-f445b2d66e5d/assets/graphic/indexer_2021_23_fig1.jpg)

Figure 1. One indexing student’s experience of online tutorials in the SI training course

[Open in viewer](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F1)

As a tutor, collating everyone’s responses to discussion topics, and then attempting to explain one’s own approach with clarity and unambiguity, is very time-consuming. Tutors need to repeat each tutorial several times before they have encountered all the issues that might arise from a given text – we only finalize the topics to cover after seeing the set of indexes each cohort of students has produced. I found it quite challenging articulating my own indexing thought processes, many of which have become rather automatic. Knowing that my reasoning would be scrutinized by a keen set of eyes made me think about my approach extremely carefully, and I prevaricated on the wording and organization of my index a lot more than usual! Other tutors have ‘confessed’ that they have tweaked their own indexes to incorporate good features from student indexes.

As I was compiling my own index in preparation for the tutorial, I annotated the text PDF with notes to myself, flagging up decisions I had made and alternative approaches I had considered but rejected. I am glad I did this, as by the time the tutorial ran some weeks later I had forgotten these details. When I shared my index (which I emphasized was _not_ a ‘model index’) I included many annotations explaining my approach to certain headings and suggesting other approaches that could have worked equally well. I would anticipate adding to these annotations during later iterations of the tutorial, to reflect any new issues and queries that will inevitably arise.

For many student indexers the degree of subjectivity involved in indexing can be a revelation; I deliberately included ‘it depends!’ in several of my email posts to drive this point home. One key take-home message – again, less obvious to students – from any peer review exercise is that there is no single ‘right’ way to approach an index. Different indexers will produce different versions of an index, but successful indexes will all display the basic principles of good indexing practice, give adequate access to the text and be helpfully organized for the user. Students also learn that there are certainly some ‘wrong’ ways to index, and it is usual for them to make some indexing errors during the tutorials. By comparing one another’s indexes in a constructive way and considering what works best for the text at hand, students can learn from their mistakes.

At the close of each tutorial, students are asked to provide feedback, including a reflection on whether they feel more (or less) confident taking their next indexing tests. The responses to the latter are usually a mix: it depends! It is quite common for students to feel less confident about the tests if they have been exposed to things that they didn’t know they didn’t know. Tutors try to explicitly link points they make to relevant sections of the training course, so that those students who are earlier in the course at least know that they will meet this again, and those who have already covered it know where to look to reinforce their learning. Confidence gains may therefore take time. Finally, after each tutorial the tutor reports back to the other tutors and the online tutorials coordinator, and reflection on student feedback is an important part of this.

## Informal student-led peer review exercises

In an initiative which pre-dated (just) the introduction of formal online tutorials, in 2006 and 2007 a small group of student indexers at different stages in the SI training course organized a programme of student-led peer review exercises, coordinated via email. In addition to the core group, other students joined in for one or two of the seven or eight texts that were indexed altogether. The texts selected were deliberately short (750–3,000 words) and were aimed at a general readership. Students spent around a week indexing the text; the indexes were then collated by the coordinator and circulated (not anonymously: guidance subsequently written by group member (and now SI tutor) David Green and available on the student website states that ‘anonymous peer reviewing offers no advantages and actually impedes discussion’). The discussion phase was fairly short, lasting three to four days. To quote from the guidance,

> Sessions worked best when all participants were actively involved and when the coordinator had time to provide a framework for discussion (identifying key learning points, channelling feedback, and involving all group members, etc.). All participants said they valued the opportunity simply to compare a variety of different indexes to the same text. This remained true even if there was little actual discussion and cross-reviewing among the group afterwards. Participants welcomed sharing tips and seeing how other students tackled thorny ‘problem areas’ in the text. It encouraged them to try out new styles and approaches to indexing, and reflect on things they may not have thought about previously. Peer reviewing proved to be a worthwhile exercise as well as a valuable source of encouragement and motivation.<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn3" role="doc-noteref" id="body-ref-fn3">3</a></sup>

To my knowledge (and that of the SI training team), this exercise has not been repeated for some years, but as a simple mechanism for enabling students to compare their approaches to indexing short texts, and sharing their learning as they progress through the training course, it should be encouraged.

## Local group peer review exercises (meeting in person)

The SI has several regional groups for organizing local get-togethers for qualified and student indexers. Not all groups incorporate specific indexing-related meetings into their calendars (although when a group of indexers get together we will inevitably discuss indexing matters), but of those that do, peer reviews are an obvious choice of activity. My own group (Yorkshire) holds one annually, and in the 2015–19 period another group (East Anglia) has organized three, and several others (East Midlands, Three Choirs, Sussex, Scotland) one.<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn4" role="doc-noteref" id="body-ref-fn4">4</a></sup> Typically six people or fewer attend these meetings.

The chosen text is circulated a few weeks before the group meets, and indexes are prepared, shared and compared. To keep things manageable the text is no more than around 20–30 pages, similar to the formal online tutorials. As group peer reviews are for indexers of all experiences and subject matter specialisms, and participants are undertaking this voluntarily, the text needs to be both accessible and sufficiently interesting to motivate people to participate. In fact it is often the most accessible and engaging texts that create the most indexing challenges and produce the widest variety of indexes. As finding suitable texts can be challenging, group coordinators share details of texts used with each other: one text (about managing pain) was used by two groups in the five-year period surveyed.

In my experience of Yorkshire group peer reviews, people come along armed with copies of their own index and a handful of accompanying caveats: ‘I had to do this at the last minute’, ‘I haven’t had time to edit it properly’, ‘I only got as far as page 14’. This is all fine, of course; peer reviews are not quality-checking exercises and no one is going to be struck off for a misspelling or wayward cross-reference. Nor are prizes awarded: as one indexer commented, ‘What makes it a pleasant experience rather than \[an\] uncomfortable one is that indexers are in general generous and kind to each other and \[we\] therefore end up with an atmosphere of constructive mutual support rather than trying to establish which index is “best”’.<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn5" role="doc-noteref" id="body-ref-fn5">5</a></sup>

We must acknowledge that peer reviews are ‘artificial’ in that documents this short would be unlikely to require the detailed, analytical indexes of the type we would normally produce. I tend to approach indexing the peer review text as if it were a section of a larger publication; however, this inevitably results in an index that feels rather clunky in places. Some people come to the meetings not having had a chance to produce an index at all, and this, too, is fine; the text and discussion around it often serve as a springboard to talk about wider indexing issues and share experiences, and everyone can contribute to this.

One of the group members leads the discussion around topics naturally arising from the text as well as obvious questions such as ‘how did you index the metatopic?’ and ‘how did you index people/places/titles of works?’ Other areas that are likely to cause lively debate include treatment of detailed figures and tables, illustrations and footnotes, and comparing approaches to subheading structure. There is less of a ‘teaching’ focus than in the formal online tutorials, of course. Some texts can produce surprising points for discussion: the pain management booklet mentioned above prompted both groups to consider the use of discursive, adjectival main entries.

If the indexes are shared on the day of the meeting, there is a lot of information to assimilate quickly and much paper shuffling around the table as we refer to our own indexes and point out features in those of our colleagues that caught our eye. Circulating indexes in advance of the meeting, as is done by the East Anglian group, for example, does not guarantee that everyone will have got around to looking at them before the meeting. What is bread-and-butter work to one indexer might be unfamiliar territory to another, so it is important to ensure everyone attending has their own queries and concerns addressed. When I facilitated a local peer review meeting, I arranged topic cards on the table which we took turns to select from ([Figure 2](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F2)). A ‘wild card’ ensured that people could introduce topics that I hadn’t thought of. This helped prioritize and focus our discussion and was a simple technique which would come into its own with larger groups or when groups include new members who may be reticent to speak out.

![](https://www.liverpooluniversitypress.co.uk/cms/10.3828/indexer.2021.23/asset/d7b3c20c-90bc-4334-9557-b3110ec776a3/assets/graphic/indexer_2021_23_fig2.jpg)

Figure 2. Topic cards used to facilitate a peer review discussion

[Open in viewer](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F2)

It would be counterproductive to marshal the conversation too rigidly, however: the conversation will naturally flow from topic to topic (I recall clearing cards from the table as our discussion naturally progressed), and participants will often illustrate points with reference to similar issues they have encountered with ‘real’ commissions, and how they addressed them. These – often candid – insights, the sort you won’t find on any training course, are gold dust.

## Local group peer review exercises (meeting over videoconference)

Thanks to COVID-19, in-person meetings could not take place from early 2020 until the time of writing. During this period the Yorkshire group has continued its programme of peer reviews by moving them to a discussion forum, described in the following section. The London group organized a peer review meeting via videoconference (Zoom). In this meeting there were five participants and four indexes, which were anonymized and circulated by the coordinator a few days in advance of the meeting. In theory this should have enabled closer analysis of the indexes prior to the meeting, but in practice the indexes were not compared in any detail. However, as with the in-person peer reviews, the peer review text provided a jumping-off point for a spontaneous and far-ranging discussion. The coordinator found chairing the discussion to be manageable with this small number of people. In my experience, chairing Zoom meetings is much harder than chairing meetings in person, due to the absence of the same visual or vocal cues that someone is burning to say something, or that people’s attention is drifting and I need to move things along. This is not the place to give detailed guidance on chairing Zoom meetings, nor am I the person to give it, but it seems that with larger groups, a more formal turn-taking structure would probably be needed to ensure that everyone has an equal voice and no one is allowed to dominate. Perhaps something similar to the topic card method I used for the in-person peer review meetings might be employed here, where people can take it in turns to pick a topic for discussion and kick things off with their insights or queries.

## Informal peer review exercises on discussion forums

### _Anne Lister of Shibden Hall_

It is gratifying when a peer review text can link in with another activity that a local group has organized. A few years ago the Yorkshire group of the SI were sufficiently inspired by indexing a publication about the town of Halifax to visit it as one of their social outings. In 2020 we had planned to follow suit, coupling a peer review exercise based on the short publication _Anne Lister of Shibden Hall_ ([Calderdale Museums, 2019](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#core-R2)) with a trip to Shibden Hall itself. (Anne Lister was a nineteenth-century diarist brought to popular attention courtesy of the television series _Gentleman Jack_.) We decided to go ahead with the peer review, but to run it on our SI online forum and open it up to all SI members, regardless of Yorkshire connections. Thirteen people, including some student indexers, got involved. Unusually for a peer review exercise, our chosen publication was not freely available online, but a handful of us had managed to purchase a copy for a modest sum and produced an index. Also unusually, I did not collect and circulate the different indexes; rather, people shared extracts from relevant sections of their indexes when they posted responses to the discussion points that I put up every few days. We frequently (and quite deliberately) wandered away from the details of this particular publication to discuss more general indexing concerns. For example, a discussion about how we handled the many illustrations prompted several people to chime in with their general approach to indexing illustrations and the influence of index space restrictions on this. To illustrate the scope of the discussion, after it had been running for around a month and was winding down, I produced a very informal index of the topics covered ([Figure 3](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F3)). A brief Google Forms survey of participants or ‘lurkers’ was completed by 11 people at the close of the exercise. Everyone surveyed had found both the text-specific discussion points, and the general discussion points, useful, even though seven out of 11 respondents had not seen or indexed the publication. One indexer commented, ‘Thanks for letting me lurk. Having last week just been given a historical biography to index, the discussions have proved very useful’, and a student indexer said, ‘As a student the interactions weren’t at all intimidating so I would definitely encourage that type of approach for future exercises. It really is so helpful to get insight to the thought processes of experienced indexers’.

![](https://www.liverpooluniversitypress.co.uk/cms/10.3828/indexer.2021.23/asset/acbf14a3-8fa3-40e3-b5be-46dd0fd47e8b/assets/graphic/indexer_2021_23_fig3.jpg)

Figure 3. Informal index to the Anne Lister peer review discussion forum

Note: the locators are page numbers in the discussion in the Yorkshire Group forum

[Open in viewer](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#F3)

### _Three men in a boat_

As another year of COVID-19 restrictions rolled around, the Yorkshire group decided to run another peer review discussion via our SI forum. I put our choice of text to a vote, and participants were overwhelmingly in support of indexing an extract from _Three men in a boat_ by Jerome K. Jerome. I think we all needed the pure escapism and light relief of the text, but indexing fiction and comedy were departures for many of us and therefore presented new challenges. This exercise, which is drawing to a close at the time of writing, is described in more detail by Paula Clarke [Bain (2021)](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#core-R1). It has been organized along similar lines to the _Anne Lister of Shibden Hall_ exercise; however, I was able to collect and circulate 15 indexes from 14 indexers, anonymized with suitably nautical pseudonyms. The promise of anonymity possibly encouraged more people to share their indexes; whilst the pseudonyms are quite fun, I am inclined to agree with David Green’s observation above, that anonymity may hinder discussion if participants are tiptoeing around issues rather than stating ‘I did X and this is why I did it’. To date I am the only indexer who has deliberately blown their own cover in order to be able to describe my own approach freely.

There are advantages and disadvantages to forum-based peer reviews compared with discussions in real time. In many respects, peer review exercises are well suited to the slower pace of asynchronous discussion. There is more time to consider and compare indexes, and to formulate responses to questions and points that other participants have raised. However, some people may be put off if they feel they need to assimilate several previous postings on a topic and have a profound insight of their own before they post anything up to add to the collective wisdom. People tend not to post up if they simply agree with what someone has already said. In contrast, when sitting around a table most people would feel no hesitancy in nodding vigorously or adding a ‘me too!’ when someone makes a point that chimes with them. As a student or newly qualified indexer, having your observations validated by experienced colleagues is intensely gratifying; there is no opportunity to ‘uptick’ posts in our forums, which might serve a similar end. To encourage people to keep the tone light and inclusive, I post up the odd short, fairly silly contribution from time to time: yes, this is deliberate, but yes, I do have a lot of fun with it too. Facilitating online forum peer reviews is much easier than chairing a meeting in person or via Zoom, and I find it very enjoyable, but it does require a reasonable time commitment.

Online forums are, of course, less ‘conversational’ than in-person meetings and there is consequently less likelihood of wandering off topic, unless the discussion is steered that way by the facilitator. (The downside to this is that there may be less incidental ‘gold dust’ on offer.) Similarly, there is less danger of anyone being able dominate the conversation; if any individuals were to spam the forum with excessive postings, they would quickly get bored when no one responded to them.

With a lack of geographic and temporal restrictions, our forum-based peer reviews have attracted more participants than any in-person exercises. There being no pressure or expectation that everyone will contribute to all discussion points, individuals can, and do, ‘lurk’ and chip in with their observations, even if they have not indexed the text. The forum is archived and searchable, leaving a record of what has been said. Whilst this has obvious utility as a future reference source, one disadvantage is that there is less likelihood of any candid ‘confessional’ sharing of experiences.

## Conclusion: the benefits of taking part in peer review exercises

The characteristics of different modes of peer review delivery are summarized in [Table 1](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#T1) and some suggested tips for running a successful peer review in [Table 2](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#T2).

Table 1. Characteristics of different modes of peer review delivery

|   | In person | Online videoconference | Online asynchronous discussion |
| --- | --- | --- | --- |
| **Attendees** | < 10 (local) | < 10, anywhere (compatible time zones) | Any number, anywhere (different time zones) |
| **Technology** | Table, chairs and refreshments | Suitable device with camera, microphone and access to Zoom, etc. | Suitable device with access to Google Groups/online forums |
| **Chairing/managing the discussion** | Be prepared to prompt about main issues and ensure participants’ priority issues are covered. Allow discussion to wander but be prepared to bring focus back to the text periodically. Moderate chairing skills required | Be more prescriptive in focusing the conversation and enabling more formal turn taking. Greater chairing skills required | Provide periodic prompts about main issues, be generally encouraging and set a light tone. Minimal chairing skills required |
| **Advantages** | Short, focused activity (often followed by a sociable meal where broader indexing issues can be discussed)  
Discussion can be free-ranging; participants can steer it towards topics of most interest to them  
Visual and vocal cues can be picked up by the facilitator, ensuring everyone is heard  
Participants often share candid insights into their own experience and indexing practice | Short, focused activity  
Participants can be anywhere (in compatible time zones)  
More time to study and compare indexes (if circulated sufficiently in advance of meeting) | Participants can dip in and out when they have time/interest in particular topics – no set time commitment  
‘Conversation’ is archived  
Participants can be anywhere  
Any number can participate  
More time to study and compare indexes |
| **Disadvantages** | Travel time – restricted to local participants  
Limited time to study and compare indexes if shared on the day | More opportunity for individuals to dominate the conversation (depending on chairing skills)  
Fewer visual/vocal cues than in-person meetings – discussion is less spontaneous | There might be a lot of discussion to ‘catch up’ on, which may put people off from posting their thoughts  
Less opportunity for spontaneous topics to arise  
Less opportunity for candid insights |

[Open in viewer](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#T1)

Table 2. Tips for running a successful peer review

•

Include an icebreaker activity, suitable for the people in the group. They can range from the challenging and creative (compose a haiku) to the simple and descriptive (what’s your favourite cake; describe your local waterway). There are probably games that could be devised along the lines of ‘who can guess the most entries that everyone has used’ – before indexes are exchanged, of course.

•

If you can, delegate finding a suitable text to someone else (this might take a lot of time).

•

Make notes about any significant indexing decisions – either annotating the source text, or the index, or both. Without them, you will forget!

•

Only anonymize indexes if you think it will encourage participation.

•

Plan broad topics to cover but be open to the discussion wandering off course.

•

Give everyone the opportunity to contribute to the discussion and use a formal mechanism to facilitate this if necessary.

•

Be especially welcoming to student and newly qualified indexers and ensure they have their specific queries addressed.

[Open in viewer](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#T2)

The main barrier to participating in a peer review exercise is time: time to find a suitable text (which is why sharing texts between different groups is so beneficial), time to produce some sort of index, and time to participate in the follow-up discussion, in person or virtually. Indexing a text of some 20–30 pages takes a disproportionate amount of time compared to indexing a similar page range in a full-length book. Peer reviews tend to be more popular with more recently qualified indexers who are less busy with indexing work, or more likely to feel that the gains to be made justify the time spent. More established indexers are often ‘too busy’. True – commitments to paid work, and well, life, will always take priority. Yet I think time spent on peer reviews _is_ time well spent.

Many, if not most, indexers are fascinated to learn how other indexers think and work. Comparing indexes to the same text, and learning why others chose to index it the way they did, is interesting and instructive. Equally fascinating, I believe, is the exercise in metacognition that peer reviews provide. Indexing for a peer review feels different to me, somehow – I am more mindful of the thought processes I am making while I index, and I try to capture some of them so that I can later remember. (Why did I choose do index this, and not that? In this way, not that way? Or even, _what was I thinking?)_

It is reassuring (especially to student and newly qualified indexers) that other indexers grapple with just the same issues: we are not alone. We all experience moments of professional doubt and uncertainty – sometimes an index will throw up completely unexpected challenges – and it is reassuring to be reminded from time to time that no two indexers will ever produce identical indexes, or even nearly identical indexes. As Helen Bilton commented, ‘I find it fascinating how very few entries there are that appear in every index. You wouldn’t think it was possible to index the same short text in so many different ways but it certainly is!’<sup><a href="https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#fn6" role="doc-noteref" id="body-ref-fn6">6</a></sup> We all bring different perspectives and approaches to the table.

I have enjoyed peer review exercises the most where the subject matter is far removed from the sorts of text I usually index. In their online tutorials, SI students are exposed to a range of types of text and subject matter, and often comment that they feel they have benefited from this, as it forces them to confront indexing issues they might otherwise choose to avoid. Similarly, deliberately leaving my comfort zone when I take part in a peer review exercise makes me feel a bit like a student again and really become reflective and self-critical about my own indexing practices. In my experience, indexers are generous with sharing their experience and enthusiasm, and

my confidence and early indexing career have been boosted thanks to the kindness of indexing colleagues. I find leading and facilitating peer reviews to be intrinsically rewarding in that it provides a perfect vehicle for me to ‘pay it forward’.

Although many of us (myself included) are fully signed-up introverts, it is still good to connect with like-minded people. Participation in peer reviews is an opportunity to do this, and I have happily grasped it, especially during the COVID-19 pandemic. Thanks to various ‘icebreaker’ activities which others have gamely gone along with (see [Table 2](https://www.liverpooluniversitypress.co.uk/doi/10.3828/indexer.2021.23#T2) for tips), I have discovered like-minded people who share my interests or my strange sense of humour. There are many people I am looking forward to meeting in person when we have our next live conference.

As I observed at the start of this article, indexing often is a solitary business. For many of us, myself included, that’s part of the appeal. But it doesn’t need to be a lonely one.

## Acknowledgements

Thanks to Nicola Green for providing her perspective on participating in SI’s online tutorials, to Ælfwine Mischler for providing information about the Index Peer Review email list, and to the following indexing colleagues for sharing their insights and experiences about attending/leading peer review exercises and commenting on earlier drafts of the article: Wendy Baskett, Helen Bilton, Rohan Bolton, David Green, Ann Hudson, Caroline Maxwell and Jan Worrall.

## Footnotes

2

Martha Osgood was awarded the 2008 Hines Award from ASI for developing the peer review process. According to the ASI website ([https://www.asindexing.org/about/awards/hines-award/#hinesrecipients](https://www.asindexing.org/about/awards/hines-award/#hinesrecipients)), ‘A broad range of fellow indexers nominated Martha for the award and documented how beneficial her peer review system has been for all indexers … \[The discussion list\] allows geographically isolated indexers the benefits gained from the peer review process’.

3

From ‘Open peer reviewing’, a document written by David Green dated February 2021. It is available in the Resources Centre of the SI Training Course website but can only be accessed by current students.

4

The New England Chapter of the American Society of Indexers (ASI) has also recently organized a similar exercise. There are, no doubt, others.

5

Helen Bilton, personal communication.

6

Helen Bilton, personal communication.

## References

Bain, P. C. (2021) ‘Meandering musings on the comic fiction index: a peer review on _Three men in a boat_’, _The Indexer_ 37(4), 245–62.

Calderdale Museums (2019) _Anne Lister of Shibden Hall_. Halifax: Calderdale Museums.

Hudson, A. (2020) ‘“A solid foundation for a career in indexing”: the story of the Society of Indexers’ training course’, _The Indexer_ 38(4), 399–417.
